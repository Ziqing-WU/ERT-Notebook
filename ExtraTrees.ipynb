{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is for the evaluation of algorithm in machine learning course at ISAE-SUPAERO, written by Ziqing WU.\n",
    "\n",
    "\n",
    "<div style=\"font-size:22pt; line-height:25pt; font-weight:bold; text-align:center;\">Extremely Randomized Trees</div>\n",
    "\n",
    "\n",
    "0. [Preliminary - Brief recall of decision tree and bagging](#sec0) \n",
    "1. [Introduction](#sec1)\n",
    "2. [Algorithm](#sec2)\n",
    "3. [Illustrations](#sec3)\n",
    "4. [Examples](#sec4)\n",
    "    1. [Spam or ham?](#sec4-1)\n",
    "    2. [NIST]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"sec0\"></a> 0. Preliminary - Brief recall of decision tree and bagging\n",
    "The extremely randomized trees is a tree-based ensemble method of supervised classification and regression problems.\n",
    "\n",
    "To get a thourough understanding of this method, the knowledge of decision tree and bagging that we have covered in class is necessary. In this section, a brief recall of these two concepts is provided. You may skip it if you feel completely comfortable with decision trees and bagging idea. \n",
    "\n",
    "## 0.1 Decision Tree\n",
    "\n",
    "Decision Tree is the hierarchical description of data based on logical (binary) questions. Based on the decision tree, several algorithms are proposed to solve classification or regression problems. They are greedy, top-down, recursive, partitioning. Here CART (Classification And Regression Trees) algorithm for classification is taken as an example. [[Rutkowski, 2014](https://www.sciencedirect.com/science/article/pii/S0020025514000206?casa_token=17o4ZXxeHmsAAAAA:XF-ClnEesKcyOCWN97d2g3RqryCxBm0gOw8qHNKirHzWj7MQQ-PB1EYVyHw70svyuzZ5T9nTXn0#s0010)]\n",
    "\n",
    "+ Algorithm starts with a single node - the root.\n",
    "+ During the learning process, in each created node, the particular subset of training set is processed. If all elements of this set are of the same class, the node will be tagged as a leaf and the split is not made. \n",
    "+ If not, the best attribute to split is chosen according to split measure function.\n",
    "+ The tree can be grown until the node is not split, meaning either the list of available attributes in the node contains only one element or all the elements from the subset are from the same class.\n",
    "\n",
    "The impurity measure used in CART is Gini index. For any subset $S_q$, the fraction of all data elements in cosidered node from class k is denoted by $p_{k,q}$. The Gini index is given by $$Gini(S_q)=1-\\sum_{k=1}^{K}(p_{k,q})^2$$\n",
    "\n",
    "It reaches its minimum (zero) when all cases fall into a single target category, and its maximum when data is equally distributed among all classes. \n",
    "\n",
    "The weighted Gini index of $S_q$ is also introduced by $$wGini(S_q, A)=p_L Gini(L_q(A))+(1-p_L)Gini(R_q(A))$$ where $A$ is the split of $S_q$, $L_q$ and $R_q$ are the two subsets derived from $S_q$ and split $A$, $p_L$ is the fraction of data elements from $S_q$ which belongs to the subset $L_q$. The Gini index of two subsets $L_q$ and $R_q$ are also calculated to deduce the weighted Gini of $S_q$. \n",
    "\n",
    "With Gini index and weighted Gini index, we can define the split measure function, called Gini gain: $$g(S_q)=Gini(S_q)-wGini(S_q, A)$$\n",
    "\n",
    "Then the optimal partition $\\tilde A$ for which Gini gain reaches its maximum is chosen among all possible partitions, showing the greedy property of this algorithm. \n",
    "\n",
    "Other split measure function can be chosen, such as cross-entropy loss. Please refer to the its [Wikipedia page](https://en.wikipedia.org/wiki/Cross_entropy) for more information.\n",
    "\n",
    "The advantages of decision tree are that it is quite easy to explain and interpret, relatively fast with time complexity proportional to the multiplication of number of data points, number of features and the depth of trees. It provides also possibilities to work with categorical variables. However, its disadvantages are quite obvious. Decision tree has high variance, meaning a small variation in data can result in a completely different tree. It can easily lead to overfitting by creating a too complex model. Greedy algorithms cannot guarantee to return the globally optimal decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 Bagging\n",
    "\n",
    "As we have seen for the decision trees, its high variance makes it difficult to provide an accurate prediction comparing to other algorithms. In 1990s, ensemble methods were put forward to combine the predictions of several base estimators built with a given learning algorithm. The objective is to improve robustness over a single estimator. \n",
    "\n",
    "Two main families of ensemble methods are identified:\n",
    "+ The averaging methods: Several independent estimators are built and then their estimations are averaged, the variance is reduced comparing to single estimators. These methods work best with strong and complex models, such as fully developed decision trees. \n",
    "+ The boosting methods: base estimators are built sequentially with objective to reduce the bias of the combined estimator. These methods are more adapted to weak models, such as shallow decision trees.\n",
    "\n",
    "In this notebook, we are interested in the averaging methods, with a particular focus on extremely randomized trees. So we may ask what is the principle for the averaging methods? Here a bootstrap aggregating (bagging) idea will be introduced [[Brieman, 1996](https://link-springer-com.rev-doc.isae.fr/article/10.1007/BF00058655)].\n",
    "\n",
    "A learning set of $\\mathcal{L}$ consists of data $\\{(y_n,\\mathbf{x}_n), n = 1,...,N\\}$ where $y_n$ is class label or a numerical response. Assume that a predictor $\\varphi(x,\\mathcal{L})$ is available to predict $y$ with the input $\\mathbf{x}$. Suppose that we have a sequence of learning sets $\\{\\mathcal{L}_k\\}$ each consisting of $N$ independent observations from the same underlying distribution as $\\mathcal{L}$. The objective is to use the $\\{\\mathcal{L}_k\\}$ to get a better predictor than the single learning set predictor $\\varphi(x,\\mathcal{L})$. The restriction is that we are only allowed to work with the sequence of predictors $\\{\\varphi(\\mathbf{x},\\mathcal{L}_k)\\}$.\n",
    "\n",
    "If $y$ is numerical, the average of $\\varphi(x,\\mathcal{L}_k)$ over $k$ can be used to replace $\\varphi(x,\\mathcal{L})$. If $y$ is a class label, then one method of aggregating the $\\varphi(x,\\mathcal{L}_k)$ is by voting. The class label predicted of a certain input is determined by the number of votes for each class among all predictors $\\{\\varphi(\\mathbf{x},\\mathcal{L}_k)\\}$. The class with most votes is the predicted class for this input.\n",
    "\n",
    "In practice, we usually have a single learning set $\\mathcal{L}$. So we imite the process by taking repeated bootstrap samples from $\\mathcal{L}$ to form a sequence of learning sets. This procedure is called Bagging (\"bootstrap aggregating\"). The learning sets bootstraped approximates the distribution underlying $\\mathcal{L}$. \n",
    "\n",
    "A critical factor in whether bagging will improve accuracy is the stability of the procedure for constructing $\\varphi$. If changes in $\\mathcal{L}$ produces small changes in $\\varphi$, then $\\varphi_B$ will be close to $\\varphi$. Improvement will occur for unstable procedures where a small change in $\\mathcal{L}$ can produce large changes in $\\varphi$. For instance, trees and neural networks can be improved by bagging method.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want more information on these two topics, don't hesitate to check the following links:\n",
    "+ [Decision Tree notebook used in class](https://github.com/erachelson/MLclass/blob/master/8%20-%20Decision%20Trees/Decision%20Trees.ipynb)\n",
    "+ [Bagging notebook used in class](https://github.com/erachelson/MLclass/blob/master/10%20-%20Bagging/Bagging.ipynb)\n",
    "+ [Page scikit learn for decision trees](https://scikit-learn.org/stable/modules/tree.html)\n",
    "+ [Page scikit learn for ensemble methods](https://scikit-learn.org/stable/modules/ensemble.html#)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"sec1\"></a> 1. Introduction\n",
    "Tree-based methods like CART (Classification And Regression Trees) has high variance. Models induced by these are to a large extent random, and also the splits, both attributes and cut-points that are chosen at each internal node depend on the random nature of learning sample. This high variance is a main reason for the relative poor accuracy obtained by tree-based methods. The \"Bagging\" idea is came up to reduce the variance of a learning algorithm without increasing its bias too much. It introduces randomization into the learning algorithm and exploit at each run a different randomized version of the learning sample, in order to provide an ensemble of diversified models. The predictions of these models are then aggregated by an average for regression problem and a majority vote for classification. \n",
    "\n",
    "Using bagging based on decision trees is an attractive idea because in one way, the accuracy can be improved by bagging comparing to single model, in the other way, the computational cost remains to be low even growing several models is required. In this sense, several techniques for introducing randomness in growing a forest of trees are proposed. We can cite the random subspace method [[Ho, 1998](https://ieeexplore.ieee.org/document/709601)], random forest [[Breiman, 2001](https://link.springer.com/article/10.1023/A:1010933404324)], perfect random tree ensembles [[Cutler, 2001](https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.232.2940&rep=rep1&type=pdf)], etc. These methods cause perturbations in the induced models by modifying the algorithm responsible for the search of the optimal split during tree growing. \n",
    "\n",
    "These methods randomize the standard tree growing algorithm to some extent, but are still far from totally random trees. It is quite interesting to investigate whether higher level of randomization can improve accuracy with respect to the above methods. This is why extremly randomized trees are proposed to select the cut-point fully at random for a given numerical attribute [[Geurts, 2006](https://link.springer.com/article/10.1007/s10994-006-6226-1)]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"sec2\"></a> 2. Algorithm\n",
    "The Extremly Randomized Trees (Extra-Trees) algorithm builds an ensemble of unpruned decision or regression trees according to the top down procedure. The two main characteristics of this algorithm are :\n",
    "+ It splits nodes by choosing cut-points fully at random.\n",
    "+ It uses the whole learning sample to grow the trees.\n",
    "\n",
    "Before going into the details of the algorithm, some terms need to be explained:\n",
    "+ *attribute*: a partucular input variable used in a supervised learning problem.\n",
    "+ *candidate attributes*: all input variables that are available for a given problem.\n",
    "+ *output*: target variable that defined the supervised learning problem.\n",
    "\n",
    "The algorithm is described as below:\n",
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "**Split_a_node($S$)**\n",
    "    \n",
    "Input: the local learning subset $S$ corresponding to the node we want to split\n",
    "    \n",
    "Output: a split $[a<a_c]$ or nothing\n",
    "\n",
    "+ If **Stop_split($S$)** is TRUE then return nothing.\n",
    "+ Otherwise select K attributes $\\{a_1,...,a_K\\}$ among all non constant (in $S$) candidate attributes;\n",
    "+ Draw K splits $\\{s_1,...,s_K\\}$, where $s_i$ = **Pick_a_random_split**($S$,$a_i$), $\\forall i = 1,...,K$;\n",
    "+ Return a split $s_*$ such that $Score(s_*, S) = max_{i=1,...,K}Score(s_i,S)$\n",
    "    \n",
    "**Pick_a_random_split($S,a$)**    \n",
    "Inputs: a subset $S$ and an attribute $a$\n",
    "    \n",
    "Output: a split\n",
    "\n",
    "+ Let $a_{max}^S$ and $a_{min}^S$ denote the maximal and minimal value of $a$ in $S$;\n",
    "+ Draw a random cut-point $a_c$ uniformly in $[a_{min}^S,a_{max}^S]$;\n",
    "+ Return the split $[a<a_c]$\n",
    "    \n",
    "**Stop_split**\n",
    "\n",
    "Input: a subset $S$\n",
    "    \n",
    "Output: a boolean\n",
    "\n",
    "+ If $|S|<n_{min}$, then return TRUE;\n",
    "+ If all attributes are constant in $S$, then return TRUE;\n",
    "+ If the output is constant in $S$, then return TRUE;\n",
    "+ Otherwise, return FALSE.\n",
    "\n",
    "</div>\n",
    "\n",
    "The two parameters in Extra-Trees are:\n",
    "+ K: the number of attributes randomly selected at each node.\n",
    "+ $n_{min}$: the minimum sample size for splitting a node.\n",
    "\n",
    "The learning sample is used several times (denoted $M$) to generate an ensemble model. The predictions of the trees are then aggregated to yield the final prediction, using arithmetic average in regression problems or majority vote in classification problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bias-Variance**\n",
    "+ Reducing variance by explicit randomization of the cut-point and attribute combined with ensemble averaging.\n",
    "+ Minimizing bias by the usage of the full original learning sample rather that bootstrap replicas\n",
    "\n",
    "**Complexity**\n",
    "\n",
    "Assumption: balanced trees\n",
    "\n",
    "The complexity is $NlogN$ with respect to learning sample size. But comparing to other methods which locally optimize cut-points, simply pick a split randomly may reduce the constant factor.\n",
    "\n",
    "**Regularization of Extra-Trees**\n",
    "\n",
    "+ K: the strength of attribute selection process\n",
    "+ $n_{min}$: the strength of averaging output noise\n",
    "+ M: the strength of the variance reduction of the ensemble model aggregation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"sec3\"></a> 3. Illustrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library import\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"sec4\"></a> 4. Examples \n",
    "\n",
    "In this section, two examples that we have been used during AML courses are implemented to facilitate the comparaison with other algorithms.\n",
    "\n",
    "## <a id=\"sec4-1\"></a> 4.1 Spam or ham?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded\n"
     ]
    }
   ],
   "source": [
    "import load_spam\n",
    "spam_data = load_spam.spam_data_loader()\n",
    "spam_data.load_data()\n",
    "print(\"data loaded\")\n",
    "\n",
    "Xtrain, ytrain, Xtest, ytest = spam_data.split(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 14279)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin with training an Extra-Trees on this tf-idf data and evaluate its generalization performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** done!\n",
      "Average generalization score: 0.9725083986562151\n",
      "Standard deviation: 0.005246154421273316\n",
      "CPU times: user 1min 17s, sys: 1.12 s, total: 1min 18s\n",
      "Wall time: 1min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "spam_ET = ExtraTreesClassifier(n_estimators=200, criterion='entropy')\n",
    "spam_ET.fit(Xtrain,ytrain)\n",
    "\n",
    "spam_ET.score(Xtest.toarray(),ytest)\n",
    "\n",
    "# Compute cross-validation score\n",
    "nb_trials = 20\n",
    "score = []\n",
    "for i in range(nb_trials):\n",
    "    Xtrain, ytrain, Xtest, ytest = spam_data.shuffle_and_split(2000)\n",
    "    spam_ET = ExtraTreesClassifier(n_estimators=200, criterion='entropy')\n",
    "    spam_ET.fit(Xtrain,ytrain);\n",
    "    score += [spam_ET.score(Xtest,ytest)]\n",
    "    print('*', end='')\n",
    "print(\" done!\")\n",
    "\n",
    "print(\"Average generalization score:\", np.mean(score))\n",
    "print(\"Standard deviation:\", np.std(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then let's evaluate how the same Extra-Trees classifier trained on raw word counts performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, ytrain, Xtest, ytest = spam_data.split(2000, feat='wordcount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** done!\n",
      "Average generalization score: 0.9805151175811873\n",
      "Standard deviation: 0.005714378867714702\n",
      "CPU times: user 1min 12s, sys: 824 ms, total: 1min 13s\n",
      "Wall time: 1min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "spam_ET = ExtraTreesClassifier(n_estimators=200, criterion='entropy')\n",
    "spam_ET.fit(Xtrain,ytrain)\n",
    "\n",
    "spam_ET.score(Xtest.toarray(),ytest)\n",
    "\n",
    "# Compute cross-validation score\n",
    "nb_trials = 20\n",
    "score = []\n",
    "for i in range(nb_trials):\n",
    "    Xtrain, ytrain, Xtest, ytest = spam_data.shuffle_and_split(2000, feat='wordcount')\n",
    "    spam_ET = ExtraTreesClassifier(n_estimators=200, criterion='entropy')\n",
    "    spam_ET.fit(Xtrain,ytrain);\n",
    "    score += [spam_ET.score(Xtest,ytest)]\n",
    "    print('*', end='')\n",
    "print(\" done!\")\n",
    "\n",
    "print(\"Average generalization score:\", np.mean(score))\n",
    "print(\"Standard deviation:\", np.std(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"sec4-2\"></a> 4.2 NIST?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n",
      "(1797, 8, 8)\n",
      "(1797,)\n",
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "print(digits.data.shape)\n",
    "print(digits.images.shape)\n",
    "print(digits.target.shape)\n",
    "print(digits.target_names)\n",
    "\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "Xtrain,Xtest = np.split(X,[1000])\n",
    "ytrain,ytest = np.split(y,[1000])\n",
    "\n",
    "def shuffle_and_split(X,y,n):\n",
    "    X0,y0 = shuffle(X,y)\n",
    "    Xtrain,Xtest = np.split(X0,[n])\n",
    "    ytrain,ytest = np.split(y0,[n])\n",
    "    return Xtrain, ytrain, Xtest, ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 64)\n",
      "(1000,)\n",
      "Generalization error: 0.05269761606022585\n",
      "Generalization score: 0.9473023839397742\n",
      "Confusion matrix:\n",
      "[[78  0  0  0  1  0  0  0  0  0]\n",
      " [ 0 74  0  1  0  1  0  0  0  4]\n",
      " [ 1  1 68  4  0  0  0  0  0  3]\n",
      " [ 0  0  0 69  0  1  0  4  5  0]\n",
      " [ 0  0  0  0 79  0  0  2  0  2]\n",
      " [ 0  0  0  0  0 80  2  0  0  0]\n",
      " [ 0  1  0  0  0  0 79  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 80  0  0]\n",
      " [ 0  2  1  0  1  1  0  0 70  1]\n",
      " [ 0  0  0  1  0  2  0  0  0 78]]\n"
     ]
    }
   ],
   "source": [
    "print(Xtrain.shape)\n",
    "print(ytrain.shape)\n",
    "digits_et = ExtraTreesClassifier(n_estimators=200, criterion='entropy')\n",
    "digits_et.fit(Xtrain,ytrain)\n",
    "prediction = digits_et.predict(Xtest)\n",
    "print(\"Generalization error:\", np.sum(np.not_equal(prediction,ytest))/len(ytest) )\n",
    "print(\"Generalization score:\", digits_et.score(Xtest,ytest))\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(ytest, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** done!\n",
      "Average generalization score: 0.9794855708908405\n",
      "Standard deviation: 0.0058080110036432325\n"
     ]
    }
   ],
   "source": [
    "# Compute cross-validation score\n",
    "nb_trials = 20\n",
    "score = []\n",
    "for i in range(nb_trials):\n",
    "    Xtrain, ytrain, Xtest, ytest = shuffle_and_split(X,y,1000)\n",
    "    digits_et = ExtraTreesClassifier(n_estimators=200, criterion='entropy')\n",
    "    digits_et.fit(Xtrain,ytrain)\n",
    "    score += [digits_et.score(Xtest,ytest)]\n",
    "    print('*',end='')\n",
    "print(\" done!\")\n",
    "\n",
    "print(\"Average generalization score:\", np.mean(score))\n",
    "print(\"Standard deviation:\", np.std(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain\n",
    "Xtrain = X[:1000,:]\n",
    "ytrain = y[:1000]\n",
    "Xtest = X[1000:,:]\n",
    "ytest = y[1000:]\n",
    "digits_et = ExtraTreesClassifier(n_estimators=200, criterion='entropy')\n",
    "digits_et.fit(Xtrain,ytrain);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAECCAYAAADXWsr9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAALx0lEQVR4nO3d0Ysd9RnG8efpmqDRyEJNJRpJKpSACNkECZWApIlKrJJ60YsELERa4kUrCS2I9ibmH5DkogghagVjRKMbirTWgC4itNokrjW6sWiIuI26EYmJBhqiby/OpKTrtjsb5zfn7L7fDxxy9uzZed/N8pyZOWdmXkeEAMxs3+l2AwDKI+hAAgQdSICgAwkQdCABgg4k0BNBt73G9ru237N9f+Faj9oes32oZJ3z6l1j+2XbI7bftr2pcL2Lbb9u+82q3taS9aqafbbfsP186VpVvaO237I9bHt/4Vr9tvfYPlz9DW8sWGtx9Tudu520vbmRhUdEV2+S+iS9L+laSbMlvSnpuoL1bpK0TNKhln6/+ZKWVffnSvpH4d/Pki6r7s+S9JqkHxb+HX8t6UlJz7f0f3pU0hUt1Xpc0i+q+7Ml9bdUt0/Sx5IWNrG8XlijL5f0XkQciYgzkp6S9JNSxSLiFUmflVr+BPU+ioiD1f1TkkYkXV2wXkTEF9WXs6pbsaOibC+QdLuknaVqdIvty9VZMTwiSRFxJiJOtFR+taT3I+KDJhbWC0G/WtKH5309qoJB6CbbiyQtVWctW7JOn+1hSWOS9kVEyXrbJN0n6euCNcYLSS/aPmB7Y8E610o6Lumxatdkp+1LC9Y73zpJu5taWC8E3RM8NuOOy7V9maRnJW2OiJMla0XEVxExIGmBpOW2ry9Rx/YdksYi4kCJ5f8fKyJimaTbJP3S9k2F6lykzm7ewxGxVNKXkoq+hyRJtmdLWivpmaaW2QtBH5V0zXlfL5B0rEu9FGF7ljoh3xURz7VVt9rMHJK0plCJFZLW2j6qzi7XKttPFKr1HxFxrPp3TNKgOrt/JYxKGj1vi2iPOsEv7TZJByPik6YW2AtB/5ukH9j+fvVKtk7SH7rcU2NsW519vJGIeKiFevNs91f3L5F0s6TDJWpFxAMRsSAiFqnzd3spIu4qUesc25fannvuvqRbJRX5BCUiPpb0oe3F1UOrJb1TotY469XgZrvU2TTpqog4a/tXkv6szjuNj0bE26Xq2d4taaWkK2yPStoSEY+UqqfOWu9nkt6q9psl6bcR8cdC9eZLetx2nzov5E9HRCsfe7XkSkmDnddPXSTpyYh4oWC9eyXtqlZCRyTdXbCWbM+RdIukexpdbvVWPoAZrBc23QEURtCBBAg6kABBBxIg6EACPRX0woczdq0W9ajX7Xo9FXRJbf5ntvqHox71ulmv14IOoIAiB8zY5iicBs2fP3/KP3P69GnNmTPngupdddVVU/6Z48ePa968eRdU78CBts+Jmdki4hsninX9EFhM7p57Gj0aclJbtmxptV51OCsKYtMdSICgAwkQdCABgg4kQNCBBAg6kABBBxIg6EACtYLe5sgkAM2bNOjVRQZ/p84laK+TtN72daUbA9CcOmv0VkcmAWhenaCnGZkEzFR1TmqpNTKpOlG+7XN2AdRQJ+i1RiZFxA5JOyROUwV6TZ1N9xk9MgnIYNI1etsjkwA0r9aFJ6o5YaVmhQEojCPjgAQIOpAAQQcSIOhAAgQdSICgAwkQdCABgg4kwKSWCzAwMNBqvbYnp2zdurXVeiiPNTqQAEEHEiDoQAIEHUiAoAMJEHQgAYIOJEDQgQQIOpAAQQcSqDOS6VHbY7YPtdEQgObVWaP/XtKawn0AKGjSoEfEK5I+a6EXAIWwjw4k0NhpqsxeA3pXY0Fn9hrQu9h0BxKo8/Habkl/kbTY9qjtn5dvC0CT6gxZXN9GIwDKYdMdSICgAwkQdCABgg4kQNCBBAg6kABBBxIg6EACjmj+sPS2j3Xv7+9vs5yGhoZarXfixIlW661cuXJG19u2bVur9dr8/U6dOqWzZ896/OOs0YEECDqQAEEHEiDoQAIEHUiAoAMJEHQgAYIOJEDQgQQIOpBAnYtDXmP7Zdsjtt+2vamNxgA0p8513c9K+k1EHLQ9V9IB2/si4p3CvQFoSJ3Zax9FxMHq/ilJI5KuLt0YgOZMaR/d9iJJSyW9VqQbAEXUHslk+zJJz0raHBEnJ/g+s9eAHlUr6LZnqRPyXRHx3ETPYfYa0LvqvOtuSY9IGomIh8q3BKBpdfbRV0j6maRVtoer248L9wWgQXVmr70q6RuXpgEwfXBkHJAAQQcSIOhAAgQdSICgAwkQdCABgg4kQNCBBGqf1NLL7rzzzlbrLVmypNV627dvb7Xe5s2bW6334IMPtlpv7969rdZre3beRFijAwkQdCABgg4kQNCBBAg6kABBBxIg6EACBB1IgKADCRB0IIE6V4G92Pbrtt+sZq9tbaMxAM2pc6z7vyStiogvquu7v2r7TxHx18K9AWhInavAhqQvqi9nVTcGNADTSK19dNt9tocljUnaFxHMXgOmkVpBj4ivImJA0gJJy21fP/45tjfa3m97f8M9AviWpvSue0SckDQkac0E39sRETdExA3NtAagKXXedZ9nu7+6f4mkmyUdLtwXgAbVedd9vqTHbfep88LwdEQ8X7YtAE2q86773yUtbaEXAIVwZByQAEEHEiDoQAIEHUiAoAMJEHQgAYIOJEDQgQRmxOy1gYGBbrdQ1KZNm7rdQlGff/55q/XanvXWC1ijAwkQdCABgg4kQNCBBAg6kABBBxIg6EACBB1IgKADCRB0IIHaQa+GOLxhmwtDAtPMVNbomySNlGoEQDl1RzItkHS7pJ1l2wFQQt01+jZJ90n6ulwrAEqpM6nlDkljEXFgkucxew3oUXXW6CskrbV9VNJTklbZfmL8k5i9BvSuSYMeEQ9ExIKIWCRpnaSXIuKu4p0BaAyfowMJTOlSUhExpM7YZADTCGt0IAGCDiRA0IEECDqQAEEHEiDoQAIEHUiAoAMJOCKaX6jd/EJ7yMqVK1utNzw8PKPrDQ0NtVpvw4YNrdZrW0R4/GOs0YEECDqQAEEHEiDoQAIEHUiAoAMJEHQgAYIOJEDQgQQIOpBArWvGVZd6PiXpK0lnuaQzML1M5eKQP4qIT4t1AqAYNt2BBOoGPSS9aPuA7Y0lGwLQvLqb7isi4pjt70naZ/twRLxy/hOqFwBeBIAeVGuNHhHHqn/HJA1KWj7Bc5i9BvSoOtNUL7U999x9SbdKOlS6MQDNqbPpfqWkQdvnnv9kRLxQtCsAjZo06BFxRNKSFnoBUAgfrwEJEHQgAYIOJEDQgQQIOpAAQQcSIOhAAgQdSGAq56Oj0vassIGBgVbrLVy4sNV6g4ODrdbLiDU6kABBBxIg6EACBB1IgKADCRB0IAGCDiRA0IEECDqQAEEHEqgVdNv9tvfYPmx7xPaNpRsD0Jy6x7pvl/RCRPzU9mxJcwr2BKBhkwbd9uWSbpK0QZIi4oykM2XbAtCkOpvu10o6Lukx22/Y3lkNcvgvtjfa3m97f+NdAvhW6gT9IknLJD0cEUslfSnp/vFPYiQT0LvqBH1U0mhEvFZ9vUed4AOYJiYNekR8LOlD24urh1ZLeqdoVwAaVfdd93sl7arecT8i6e5yLQFoWq2gR8SwJPa9gWmKI+OABAg6kABBBxIg6EACBB1IgKADCRB0IAGCDiTgiGh+oXbzC01s7969rdZbtGhRq/Xani0300WExz/GGh1IgKADCRB0IAGCDiRA0IEECDqQAEEHEiDoQAIEHUhg0qDbXmx7+LzbSdubW+gNQEMmvWZcRLwraUCSbPdJ+qekwbJtAWjSVDfdV0t6PyI+KNEMgDKmGvR1knaXaARAObWDXl3Tfa2kZ/7H95m9BvSougMcJOk2SQcj4pOJvhkROyTtkDhNFeg1U9l0Xy8224FpqVbQbc+RdIuk58q2A6CEuiOZTkv6buFeABTCkXFAAgQdSICgAwkQdCABgg4kQNCBBAg6kABBBxIg6EACpWavHZd0IeesXyHp04bb6YVa1KNeW/UWRsS88Q8WCfqFsr0/Im6YabWoR71u12PTHUiAoAMJ9FrQd8zQWtSjXlfr9dQ+OoAyem2NDqAAgg4kQNCBBAg6kABBBxL4N800havBlCuWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction on image number 1053 : [4]\n",
      "correct label                : 4\n"
     ]
    }
   ],
   "source": [
    "N = 1053\n",
    "plt.gray();\n",
    "plt.matshow(digits.images[N]) \n",
    "plt.show() \n",
    "x = digits.data[N,:]\n",
    "print(\"prediction on image number\", N, \":\", digits_et.predict([digits.data[N,:]]))\n",
    "print(\"correct label                :\", digits.target[N])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find misclassified examples\n",
    "ypredict = digits_et.predict(Xtest)\n",
    "misclass = np.not_equal(ypredict, ytest)\n",
    "Itest = digits.images[1000:,:]\n",
    "Xmisclass = Xtest[misclass,:]\n",
    "ymisclass = ytest[misclass]\n",
    "Imisclass = Itest[misclass,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction on image number 1 : [3]\n",
      "correct label                : 8\n"
     ]
    }
   ],
   "source": [
    "# Display misclassified examples\n",
    "N = 1\n",
    "plt.matshow(Imisclass[N]) \n",
    "plt.show() \n",
    "print(\"prediction on image number\", N, \":\", digits_et.predict([Xmisclass[N,:]]))\n",
    "print(\"correct label                :\", ymisclass[N])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "importances = digits_rf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in digits_rf.estimators_], axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "fig=plt.figure(figsize=(10,10), dpi= 80, facecolor='w', edgecolor='k')\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices], color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "importances_image = importances.reshape((8,8))\n",
    "plt.imshow(importances_image);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
